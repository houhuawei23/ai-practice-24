{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CLIP model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Paths to data\n",
    "template_path = \"./LicensePlateDataTest/Character_templates\"\n",
    "plate_path = \"./LicensePlateDataTest/License_plate\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load character templates\n",
    "templates = []\n",
    "labels = []\n",
    "for file in os.listdir(template_path):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        img_path = os.path.join(template_path, file)\n",
    "        template_img = cv2.imread(img_path)\n",
    "        _, binary_img = cv2.threshold(template_img, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "        # cv2.imshow(\"binary_img\", binary_img)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "        # break\n",
    "        img = preprocess(Image.fromarray(binary_img)).unsqueeze(0).to(device)\n",
    "        templates.append(img)\n",
    "        labels.append(os.path.splitext(file)[0])  # Use file name as label\n",
    "\n",
    "templates = torch.cat(templates, 0)\n",
    "\n",
    "# Encode character templates with CLIP\n",
    "with torch.no_grad():\n",
    "    template_features = model.encode_image(templates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show img templates[0]\n",
    "# img0 = np.transpose(np.array(templates[0]), (1, 2, 0))\n",
    "# cv2.imshow('img', img0)\n",
    "# img0.shape\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "# binary_img.shape\n",
    "\n",
    "def show_tensor_img(tensor_img):\n",
    "    img_numpy = np.transpose(np.array(tensor_img), (1, 2, 0))\n",
    "    cv2.imshow('img', img_numpy)\n",
    "    print(img_numpy.shape)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "show_tensor_img(templates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65, 3, 224, 224])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template_features.shape\n",
    "templates.shape\n",
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_characters(image, num_chars=7):\n",
    "#     \"\"\"Divide the image into character regions.\"\"\"\n",
    "#     h, w = image.shape\n",
    "#     char_width = w // num_chars\n",
    "#     return [image[:, i * char_width : (i + 1) * char_width] for i in range(num_chars)]\n",
    "\n",
    "\n",
    "def extract_characters(image, num_chars=7):\n",
    "    \"\"\"Divide the image into character regions.\"\"\"\n",
    "    h, w = image.shape\n",
    "    x_range_list = [\n",
    "        (10, 65),\n",
    "        (70, 125),\n",
    "        (145, 200),\n",
    "        (200, 255),\n",
    "        (255, 310),\n",
    "        (315, 370),\n",
    "        (370, 425),\n",
    "    ]\n",
    "    y_range = (20, 120)\n",
    "    # char_width = w // num_chars\n",
    "    # return [image[:, i * char_width : (i + 1) * char_width] for i in range(num_chars)]\n",
    "    characters_images = []\n",
    "    for x_range in x_range_list:\n",
    "        x_min, x_max = x_range\n",
    "        characters_images.append(image[y_range[0] : y_range[1], x_min:x_max])\n",
    "\n",
    "    return characters_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plate_path \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(plate_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mahy1N6L77_blue_False.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m plate_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(plate_path, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[1;32m      3\u001b[0m _, binary_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(plate_img, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m255\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY_INV)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "plate_path = os.path.join(plate_path, \"ahy1N6L77_blue_False.jpg\")\n",
    "plate_img = cv2.imread(plate_path, cv2.IMREAD_GRAYSCALE)\n",
    "_, binary_img = cv2.threshold(plate_img, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Extract characters\n",
    "char_regions = extract_characters(binary_img)\n",
    "\n",
    "plate_text = \"\"\n",
    "for char_img in char_regions:\n",
    "\n",
    "    # Resize to match template size\n",
    "    char_img = cv2.resize(char_img, (templates.shape[-1], templates.shape[-2]))\n",
    "    # cv2.imshow(\"Char\", char_img)\n",
    "    # while True:\n",
    "    #     key = cv2.waitKey(0)\n",
    "    #     if key == ord(\"q\"):\n",
    "    #         exit()\n",
    "    #     elif key == ord(\" \"):\n",
    "    #         break\n",
    "    print(char_img.shape)   \n",
    "    char_tensor = preprocess(Image.fromarray(char_img)).unsqueeze(0).to(device)\n",
    "    show_tensor_img(char_tensor)\n",
    "    # Encode the character\n",
    "    with torch.no_grad():\n",
    "        char_features = model.encode_image(char_tensor)\n",
    "\n",
    "    # Compare to template features\n",
    "    similarity = (char_features @ template_features.T).squeeze(0)\n",
    "    best_match = similarity.argmax().item()\n",
    "\n",
    "    # Append recognized character\n",
    "    plate_text += labels[best_match]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def recognize_plate(plate_path):\n",
    "    \"\"\"Recognize license plate characters.\"\"\"\n",
    "    # Read and preprocess the plate image\n",
    "    plate_img = cv2.imread(plate_path, cv2.IMREAD_GRAYSCALE)\n",
    "    _, binary_img = cv2.threshold(plate_img, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Extract characters\n",
    "    char_regions = extract_characters(binary_img)\n",
    "\n",
    "    plate_text = \"\"\n",
    "    for char_img in char_regions:\n",
    "\n",
    "        # Resize to match template size\n",
    "        char_img = cv2.resize(char_img, (templates.shape[-1], templates.shape[-2]))\n",
    "        cv2.imshow(\"Char\", char_img)\n",
    "        while True:\n",
    "            key = cv2.waitKey(0)\n",
    "            if key == ord(\"q\"):\n",
    "                exit()\n",
    "            elif key == ord(\" \"):\n",
    "                break\n",
    "\n",
    "        char_tensor = preprocess(Image.fromarray(char_img)).unsqueeze(0).to(device)\n",
    "\n",
    "        # Encode the character\n",
    "        with torch.no_grad():\n",
    "            char_features = model.encode_image(char_tensor)\n",
    "\n",
    "        # Compare to template features\n",
    "        similarity = (char_features @ template_features.T).squeeze(0)\n",
    "        best_match = similarity.argmax().item()\n",
    "\n",
    "        # Append recognized character\n",
    "        plate_text += labels[best_match]\n",
    "\n",
    "    return plate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plate number for ahy4SD8V2_blue_False.jpg is hnq4JJJJJ\n",
      "Plate number for ahy1N6L77_blue_False.jpg is hnqJNJJJJ\n",
      "Plate number for ahy5LBR4E_blue_False.jpg is hnqJJJJ4J\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Process all plates and save results\n",
    "results = []\n",
    "for file in os.listdir(plate_path):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        full_path = os.path.join(plate_path, file)\n",
    "        plate_number = recognize_plate(full_path)\n",
    "        print(f\"Plate number for {file} is {plate_number}\")\n",
    "        results.append({\"Filename\": file, \"LicensePlate\": plate_number})\n",
    "\n",
    "# Save results to CSV\n",
    "# df = pd.DataFrame(results)\n",
    "# df.to_csv(\"results.csv\", index=False)\n",
    "# print(\"Recognition complete. Results saved to 'results.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
